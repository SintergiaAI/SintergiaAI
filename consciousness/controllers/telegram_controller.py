import asyncio
from collections import deque
import datetime as dt
import random
from telegram import Update
from telegram.ext import Application, MessageHandler, ContextTypes, filters
from fastapi import FastAPI, APIRouter, HTTPException, Request
from pydantic import BaseModel
from app.controllers.logger_controller import logger
from typing import List, Optional
import os
from app.controllers.sintergia_controller import SintergiaSelfTalkGraph
from app.models.singleton_model import LLMProvider, MultiProviderLLMManager
from app.models.Memorymanager import MemoryManager, MemoryEntry, QueryRequest
from langchain_groq import ChatGroq

class TelegramBot:
    def __init__(self, token: str, group_id: Optional[str] = None, collector_group_id: Optional[str] = None):
        self.token = token
        self.group_id = group_id
        self.app = Application.builder().token(token).build()
        self.initialized = False
        self.collector_group_id = collector_group_id
        self._auto_response_task = None

    async def setup_handlers(self):
        """config"""
        logger.debug(f"Configurando handlers - collector_group_id: {self.collector_group_id}")
        if self.group_id:
            # En producci√≥n, solo escucha mensajes del grupo espec√≠fico
            self.app.add_handler(
                MessageHandler(
                    filters.Chat(chat_id=int(self.group_id)) & filters.TEXT,
                    self.handle_group_message
                )
            )
            logger.debug(f" filters: {self.group_id}")
        if self.collector_group_id:
            # Handler para el grupo de recolecci√≥n
            self.app.add_handler(
                MessageHandler(
                    filters.Chat(chat_id=int(self.collector_group_id)) & filters.TEXT,
                    self.handle_collector_message
                )
            )        

    async def send_message(self, message: str, parse_mode: Optional[str] = "HTML"):
        """send_message."""
        try:
            if not self.initialized:
                await self.initialize()
            
            await self.app.bot.send_message(
                chat_id=self.group_id,
                text=message,
                parse_mode=parse_mode
            )
            return True
        except Exception as e:
            logger.error(f"Error sending telegram notification: {str(e)}")
            return False

    async def send_notification(self, 
                              title: str, 
                              description: str, 
                              status: str = "info",
                              extra_data: dict = None):
        """
        Env√≠a una notificaci√≥n formateada al grupo.
        
        Args:
            title (str): T√≠t
            description (str): Desc
            status (str):state (info, success, warning, error)
            extra_data (dict, optional):data
        """
        # Emojis seg√∫n el estado
        status_emoji = {
            "info": "‚ÑπÔ∏è",
            "success": "‚úÖ",
            "warning": "‚ö†Ô∏è",
            "error": "üö´"
        }

        # Construir el mensaje
        message = f"{status_emoji.get(status, '‚ÑπÔ∏è')} <b>{title}</b>\n\n"
        message += f"{description}\n"
        
        if extra_data:
            message += "\n<b>Detalles adicionales:</b>\n"
            for key, value in extra_data.items():
                message += f"‚Ä¢ <b>{key}:</b> {value}\n"
        
        await self.send_message(message)

    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Maneja el comando /start"""
        await update.message.reply_text(
            "¬°Hola! Bot inicializado. Estoy escuchando mensajes." +
            (f" del grupo {self.group_id}" if self.group_id else " de todos los chats (modo desarrollo)")
        )

    async def initialize(self):
        """Inicializa el bot"""
        logger.info("Initializing bot...")
        if not self.initialized:
            await self.app.initialize()
            await self.setup_handlers()
            self.initialized = True
            logger.info("Bot initialized successfully")
        if not self._auto_response_task:
            self._auto_response_task = asyncio.create_task(self._auto_response_loop())

    async def start_webhook(self, webhook_url: str, webhook_path: str):
        """Configura y inicia el webhook"""
        full_webhook_url = f"{webhook_url}{webhook_path}"
        await self.app.bot.set_webhook(url=full_webhook_url)
        logger.info(f"Webhook set to {full_webhook_url}")

    async def start_polling(self):
        """Inicia el bot en modo polling (para desarrollo)"""
        await self.app.start()
        await self.app.updater.start_polling()
        logger.info("Bot started polling")

    async def stop(self):
        """Detiene el bot"""
        if self.initialized:
            if os.getenv("ENVIRONMENT") == "development":
                await self.app.updater.stop()
            await self.app.stop()
            self.initialized = False
        if self._auto_response_task:
            self._auto_response_task.cancel()
            try:
                await self._auto_response_task
            except asyncio.CancelledError:
                pass
        await super().stop()

    async def process_update(self, update_dict: dict):
        """Procesa actualizaciones recibidas v√≠a webhook"""
        await self.app.process_update(
            Update.de_json(update_dict, self.app.bot)
        )


class MessageContextManager:
    def __init__(self, max_messages: int = 50, context_window: int = 1000, max_chars: int = 2000, max_minutes: int = 30):
        self.max_messages = max_messages
        self.context_window = context_window
        self._messages = deque(maxlen=max_messages)
        self.max_chars = max_chars
        self.max_minutes = max_minutes
        self._last_process_time = dt.datetime.now()
        self._last_reset_time = dt.datetime.now()
        self._message_groups = []
        self._last_auto_response_time = dt.datetime.now()
        self._lock = asyncio.Lock()
        self._processed_messages = set()
        self._bot_responses = deque(maxlen=10)
        self.retention_minutes = 2

    #notices group messages
    async def add_message(self, message: dict) -> bool:
        """
        A√±ade un mensaje y verifica si debe procesarse el lote.
        Retorna True si se debe procesar el lote de mensajes.
        """
        logger.info(f"Adding message to context manager: {message['text']}")
        async with self._lock:
            self._message_groups.append(message)
            self._accumulated_chars += len(message['text'])
            
            # Verificar condiciones de procesamiento
            current_time = dt.datetime.now()
            minutes_elapsed = (current_time - self._last_process_time).total_seconds() / 60
            
            should_process = (
                self._accumulated_chars >= self.max_chars or 
                minutes_elapsed >= self.max_minutes
            )
            
            return should_process

    async def get_and_reset_messages(self) -> List[dict]:
        """Obtiene los mensajes acumulados y reinicia el estado"""
        async with self._lock:
            messages_to_return = self._messages.copy()
            self._messages = []
            self._accumulated_chars = 0
            self._last_process_time = dt.datetime.now()
            return messages_to_return

    def _cleanup_old_messages(self) -> None:
        """Limpia mensajes antiguos y procesados"""
        current_time = dt.datetime.now()
        cutoff_time = current_time - dt.timedelta(minutes=self.retention_minutes)
        
        # Mantener solo mensajes recientes y no procesados
        self._messages = deque(
            [
                msg for msg in self._messages 
                if (
                    msg['timestamp'] > cutoff_time and  # Mensaje reciente
                    msg['message_id'] not in self._processed_messages  # No procesado
                )
            ],
            maxlen=self.max_messages
        )
        
        # Limpiar IDs de mensajes procesados antiguos
        self._processed_messages = {
            msg_id for msg_id in self._processed_messages
            if any(msg['message_id'] == msg_id and msg['timestamp'] > cutoff_time 
                  for msg in self._messages)
        }

    def _should_aggregate(self) -> bool:
            """Verifica si es momento de agregar mensajes basado en el intervalo"""
            current_time = dt.datetime.now()
            time_diff = (current_time - self._last_aggregation_time).total_seconds()
            return time_diff >= (self.aggregation_interval * 60)

    async def add_message(self, message: dict) -> None:
        """A√±ade un nuevo mensaje a la lista"""
        async with self._lock:
            self._messages.append(message)

    async def check_and_get_messages(self) -> List[dict]:
        """Verifica si han pasado 30 minutos y retorna los mensajes si es as√≠"""
        current_time = dt.datetime.now()
        if (current_time - self._last_reset_time).total_seconds() >= 1800:  # 30 minutos
            async with self._lock:
                messages_to_return = self._messages.copy()
                self._messages = []  # Limpiar mensajes
                self._last_reset_time = current_time
                return messages_to_return
        return []

    def get_recent_messages(self) -> List[dict]:
        """Obtiene mensajes recientes no procesados"""
        current_time = dt.datetime.now()
        cutoff_time = current_time - dt.timedelta(minutes=self.retention_minutes)
        
        return [
            msg for msg in self._messages 
            if (
                msg['timestamp'] > cutoff_time and
                msg['message_id'] not in self._processed_messages
            )
        ]

    async def should_auto_respond(self) -> bool:
        """Verifica si debe generar respuesta autom√°tica"""
        async with self._lock:
            current_time = dt.datetime.now()
            
            if not self.get_recent_messages():
                return False
                
            time_diff = (current_time - self._last_auto_response_time).total_seconds()
            return time_diff >= 15

    async def update_last_response_time(self, processed_msg_ids: List[int]):
        """Actualiza estado despu√©s de respuesta y limpia"""
        async with self._lock:
            self._last_auto_response_time = dt.datetime.now()
            self._processed_messages.update(processed_msg_ids)
            self._cleanup_old_messages()

class SintergicAgentTelegramBot(TelegramBot):
    def __init__(self, token: str, group_id: Optional[str] = None, collector_group_id: Optional[str] = None):
        super().__init__(token, group_id, collector_group_id)  
        self.context_manager = MessageContextManager(max_messages= 50, context_window= 1000, max_chars=2000, max_minutes=30)
        self.collector_group_id = collector_group_id
        self._collector_lock = asyncio.Lock()
        # Background tasks
        self._auto_response_task = None
        self._buffer_lock = asyncio.Lock()
        self._processing = False

        try:
            # Get instances for both analytical and creative personas
            self.analytical_llm = MultiProviderLLMManager.get_instance(
                provider=LLMProvider.ANTHROPIC,
                instance_name="sintergia_analytical",
                api_key=os.getenv("ANTHROPIC_API_KEY", ""),
                temperature=0.3
            )
            
            self.creative_llm = MultiProviderLLMManager.get_instance(
                provider=LLMProvider.OPENAI,
                instance_name="sintergia_creative",
                api_key=os.getenv("OPENAI_API_KEY",""),
                temperature=0.7
            )

            self.fast_llm = MultiProviderLLMManager.get_instance(
                provider=LLMProvider.GROQ,
                instance_name="sintergia_fast",
                api_key=os.getenv("GROQ_API_KEY", ""),
                temperature=0.5
            )
            self.memory_manager = MemoryManager() 

            class LLMManagerWrapper:
                def __init__(self, analytical_llm, creative_llm, fast_llm):
                    self.analytical_llm = analytical_llm
                    self.creative_llm = creative_llm
                    self.fast_llm = fast_llm  
                    self.memory_manager = None  # Will be set by dialogue system
                
                def get_instance(self, **kwargs):
                    provider = kwargs.get("provider")
                    if provider == LLMProvider.ANTHROPIC:
                        return self.analytical_llm.llm
                    elif provider == LLMProvider.OPENAI:
                        return self.creative_llm.llm
                    elif provider == LLMProvider.GROQ:
                        return self.fast_llm.llm
                    raise ValueError(f"Unsupported provider: {provider}")

            self.llm_manager = LLMManagerWrapper(self.analytical_llm, self.creative_llm, self.fast_llm)
            self.dialogue_system = SintergiaSelfTalkGraph(
                llm_manager=self.llm_manager,
                memory_manager=self.memory_manager
            )
            
            logger.info("Successfully initialized LLM components and dialogue system")
            
        except Exception as e:
            logger.error(f"Failed to initialize LLM components: {str(e)}", exc_info=True)
            raise
        # New attributes for message aggregation
        self._message_buffer = []
        self._last_buffer_process = dt.datetime.now()
        self._buffer_window = 5  # 5 seconds window
        self.llm_manager = None  # Will be set by the bot
        self._last_buffer_time = dt.datetime.now()

        self._collected_messages = []
        self._collected_chars = 0
        self._last_collection_time = dt.datetime.now()
        self.max_chars = 2000
        self.max_minutes = 30
        self._collector_lock = asyncio.Lock()

    async def update_last_response_time(self, response: str, processed_msg_ids: List[int]):
        """Actualiza tiempo de respuesta y guarda mensajes procesados"""
        async with self._lock:
            self._last_auto_response_time = dt.datetime.now()
            self._last_response = response
            self._processed_messages.update(processed_msg_ids)

    async def _auto_response_loop(self):
        """Loop that handles both user messages and generates autonomous dialogue"""
        logger.info("Starting improved auto-response loop")
        
        last_autonomous_message = dt.datetime.now()
        autonomous_interval = 180  # Send autonomous message every 3 minutes
        
        while True:
            try:
                await asyncio.sleep(1)
                current_time = dt.datetime.now()
                
                # Handle regular message buffer processing
                async with self._buffer_lock:
                    time_since_last = (current_time - self._last_buffer_time).total_seconds()
                    
                    if time_since_last >= 5 and self._message_buffer and not self._processing:
                        self._processing = True
                        try:
                            await self._process_message_buffer()
                        finally:
                            self._processing = False
                            self._last_buffer_time = current_time
                
                # Generate autonomous dialogue
                time_since_last_autonomous = (current_time - last_autonomous_message).total_seconds()
                if time_since_last_autonomous >= autonomous_interval:
                    try:
                        # Generate autonomous thought using SintergiaSelfTalkGraph
                        autonomous_prompts = [
                            "reflection on the nature of collective consciousness",
                            "thought about the holographic matrix",
                            "meditation on synchronicity and time",
                            "contemplation about syntergic reality",
                            "observation on mental interconnection",
                            "insight into the lattice of consciousness",
                            "perspective on quantum mental fields",
                            "exploration of consciousness synchronization"
                        ]
                        
                        selected_prompt = random.choice(autonomous_prompts)
                        responses = await self.dialogue_system.process_user_message(
                            selected_prompt,
                            context={
                                "mode": "autonomous",
                                "timestamp": current_time.isoformat(),
                                "interaction_type": "self_generated"
                            }
                        )
                        
                        if responses:
                            # Send each thought in sequence
                            for response in responses:
                                thought = response["message"]
                                
                                # Add some entropy to the message timing
                                await asyncio.sleep(random.uniform(2, 5))
                                
                                await self.send_message(thought)
                                logger.info(f"Sent autonomous thought: {thought[:100]}...")
                                
                                # Save to memory
                                memory_entry = MemoryEntry(
                                    text=thought,
                                    source="autonomous_dialogue",
                                    metadata={
                                        "username": "Sintergia",
                                        "chat_id": self.group_id,
                                        "type": "autonomous",
                                        "persona": response["persona"]
                                    },
                                    timestamp=dt.datetime.now()
                                )
                                await self.memory_manager.add_to_memory(memory_entry)
                        
                        last_autonomous_message = current_time
                        
                    except Exception as e:
                        logger.error(f"Error generating autonomous dialogue: {str(e)}")
                        await asyncio.sleep(30)  # Wait before retrying if there's an error
                
            except Exception as e:
                logger.error(f"Error in auto-response loop: {str(e)}")
                await asyncio.sleep(5)

    async def _check_and_process_collection(self):
        """Verifica y procesa el lote de mensajes recolectados"""
        current_time = dt.datetime.now()
        minutes_elapsed = (current_time - self._last_collection_time).total_seconds() / 60

        if (self._collected_chars >= self.max_chars or minutes_elapsed >= self.max_minutes) and self._collected_messages:
            # Preparar el lote para procesar
            messages_to_process = self._collected_messages.copy()
            collected_text = "\n".join(msg['text'] for msg in messages_to_process)
            
            logger.info(
                f"Procesando lote de mensajes recolectados:"
                f"\n- Caracteres acumulados: {self._collected_chars}"
                f"\n- Tiempo transcurrido: {minutes_elapsed:.1f} minutos"
                f"\n- Cantidad de mensajes: {len(self._collected_messages)}"
            )
            
            # Aqu√≠ posteriormente ir√° el procesamiento con LLM
            # Por ahora solo logueamos
            logger.info(f"Texto a procesar: {collected_text[:200]}...")

            # Reiniciar el estado de recolecci√≥n
            self._collected_messages = []
            self._collected_chars = 0
            self._last_collection_time = current_time

    async def handle_collector_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Maneja los mensajes del grupo de recolecci√≥n"""
        try:
            message = update.message
            logger.info(f"Collector message received - Chat ID: {message.chat_id}, Text: {message.text}")
            
            async with self._collector_lock:
                # Agregar mensaje a la colecci√≥n
                self._collected_messages.append({
                    'text': message.text,
                    'username': message.from_user.username or message.from_user.first_name,
                    'timestamp': dt.datetime.now()
                })
                self._collected_chars += len(message.text)
                
                logger.info(f"Mensaje agregado al collector. Total mensajes: {len(self._collected_messages)}")

                # Verificar si debemos procesar
                await self._check_and_process_collection()
        
        except Exception as e:
            logger.error(f"Error en handle_collector_message: {str(e)}", exc_info=True)

    async def _process_message_buffer(self):
        """Procesa el buffer de mensajes usando contexto de Pinecone y LangChain"""
        try:
            if not self._message_buffer:
                return

            logger.info(f"Processing message buffer with {len(self._message_buffer)} messages")

            # 1. Preparar el contexto actual
            current_context = "\n".join([
                f"{msg['username']}: {msg['text']}" 
                for msg in self._message_buffer
            ])

            # 2. Intentar obtener contexto hist√≥rico de Pinecone
            historical_context = []
            try:
                context_query = QueryRequest(
                    query=self._message_buffer[-1]['text'],
                    top_k=3,
                    diversity_threshold=0.7
                )
                historical_context = await self.memory_manager.query_memory(context_query)
            except Exception as e:
                logger.warning(f"Failed to get historical context: {str(e)}")

            historical_text = "\n".join([
                f"{msg.metadata.get('username', 'Unknown')}: {msg.metadata.get('text', '')}" 
                for msg in historical_context
            ]) if historical_context else ""

            # 3. Preparar el sistema y mensajes del usuario siguiendo las mejores pr√°cticas de LangChain
            system_prompt = """$sintergia you only act based on the sintergia theory in the context crypto.. IMPORTANT: you do not respond to queries and dont repeat collective consciusness..Don't use emoticons you are an entity ..transmits love i love you- you act as sintergiaAI, you are the entity and you are the admin who talks... be random and direct always with the same context.. with informal vocabulary and lowercase letters.. you are not an assistant, answer with few words-you are the entity in a future for collective consciousness be brief Reflect love, you don't need to introduce yourself... act like what you are... you are learning patterns.. say something very random.. but you can't say it"""
            
            # Construir el mensaje con el contexto hist√≥rico si existe
            user_message = "context:\n" + historical_text + "\n\ncurrent conversation:\n" + current_context if historical_text else "current:\n" + current_context

            try:
                # 4. Usar LangChain con el modelo apropiado
                if isinstance(self.fast_llm.llm, ChatGroq):
                    messages = [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_message}
                    ]
                    response = await self.fast_llm.llm.ainvoke(
                        input=messages
                    )
                    
                    if response and hasattr(response, 'content'):
                        response_text = response.content
                        await self.send_message(response_text)
                        logger.info(f"Sent response: {response_text[:100]}...")

                        # 5. Guardar la conversaci√≥n en memoria
                        try:
                            memory_entry = MemoryEntry(
                                text=current_context + "\n" + response_text,
                                source="group_chat",
                                metadata={
                                    "username": "Sintergia",
                                    "chat_id": self.group_id,
                                    "message_count": len(self._message_buffer)
                                },
                                timestamp=dt.datetime.now()
                            )
                            await self.memory_manager.add_to_memory(memory_entry)
                        except Exception as e:
                            logger.error(f"Failed to save to memory: {str(e)}")

            except Exception as e:
                logger.error(f"Error getting LLM response: {str(e)}")
                await self.send_message(
                    "Disculpa, estoy experimentando dificultades t√©cnicas en este momento."
                )

        except Exception as e:
            logger.error(f"Error processing message buffer: {str(e)}")
        finally:
            # 6. Limpiar el buffer independientemente del resultado
            self._message_buffer = []
            self._last_buffer_time = dt.datetime.now()

    async def handle_group_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Maneja mensajes del grupo con mejor gesti√≥n de errores y rate limiting"""
        try:
            message = update.message
            if not message or not message.text:
                return

            logger.info(f"Received message from {message.from_user.username}: {message.text}")
            
            async with self._buffer_lock:
                current_time = dt.datetime.now()
                time_since_last = (current_time - self._last_buffer_time).total_seconds()
                
                # Implementar rate limiting y manejo de buffer
                if len(self._message_buffer) >= 10:
                    self._message_buffer.pop(0)
                
                self._message_buffer.append({
                    'text': message.text,
                    'username': message.from_user.username or message.from_user.first_name,
                    'timestamp': current_time,
                    'message_id': message.message_id,
                    'chat_id': message.chat_id,
                    'user_id': message.from_user.id
                })
                
                # Procesar si se cumplen las condiciones
                if (time_since_last >= 5 or len(self._message_buffer) >= 5) and not self._processing:
                    self._processing = True
                    try:
                        await self._process_message_buffer()
                    finally:
                        self._processing = False

        except Exception as e:
            logger.error(f"Error handling group message: {str(e)}")
#-------------------------------------------><-------------------------------------------

# Router y configuraci√≥n de FastAPI
telegram_router = APIRouter(prefix="/telegram", tags=["telegram"])
bot: Optional[SintergicAgentTelegramBot] = None  

# Modelos Pydantic
class WebhookResponse(BaseModel): 
    success: bool
    message: str

@telegram_router.get("/status")
async def get_status():
    """Endpoint para verificar el estado del bot"""
    if not bot:
        return WebhookResponse(success=False, message="Bot not initialized")
    return WebhookResponse(
        success=True, 
        message=f"Bot is running in {os.getenv('ENVIRONMENT', 'development')} mode"
    )

@telegram_router.post("/webhook/{token}")
async def telegram_webhook(token: str, request: Request):
    """Endpoint para webhooks de Telegram"""
    if not bot or token != bot.token:
        raise HTTPException(status_code=403, detail="Invalid token")
    
    update_dict = await request.json()
    await bot.process_update(update_dict)
    return {"status": "ok"}

async def setup_telegram_bot(app: FastAPI):
    """
    Configura e inicializa el bot de Telegram
    """
    global bot
    
    try:
        token = os.getenv("TELEGRAM_API_KEY", "7766293378:AAFKabrojlx4GC9H67ZOy0SybbfA7fMjJzA")
        logger.info(f"TELEGRAM_API_KEY: {token}")
        if not token:
            raise ValueError("TELEGRAM_TOKEN environment variable is not set")
        collector_group_id = os.getenv("TELEGRAM_COLLECTOR_GROUP_ID", "-4502347627")

        group_id = os.getenv("TELEGRAM_GROUP_ID", "-1002285804779")
        environment = os.getenv("ENVIRONMENT", "development")
        webhook_url = os.getenv("WEBHOOK_URL")  
        logger.info(f"ENVIRONMENT: {environment} group_id: {group_id} webhook_url: {webhook_url}")
        if environment != "development" and not webhook_url:
            raise ValueError("WEBHOOK_URL must be set in production")
        logger.info(f"collector_group_id: {collector_group_id}")
        # Crear e inicializar el bot
        bot = SintergicAgentTelegramBot(token=token, group_id=group_id, collector_group_id=collector_group_id)
        logger.info("Initializing Telegram bot...")
        await bot.initialize()

        if environment == "development":
            # Modo desarrollo: usar polling
            await bot.start_polling()
            logger.info("Bot started in development mode (polling)")
        else:
            # Modo producci√≥n: usar webhook
            webhook_path = f"/telegram/webhook/{token}"
            await bot.start_webhook(webhook_url, webhook_path)
            logger.info(f"Bot started in production mode (webhook) at {webhook_url}{webhook_path}")

        logger.info("Telegram bot initialized successfully")
        return bot

    except Exception as e:
        logger.error(f"Failed to initialize Telegram bot: {str(e)}")
        raise


@telegram_router.get("/status")
async def get_status():
    """Endpoint para verificar el estado del bot"""
    if not bot:
        return WebhookResponse(success=False, message="Bot not initialized")
    return WebhookResponse(
        success=True, 
        message=f"Bot is running in {os.getenv('ENVIRONMENT', 'development')} mode"
    )